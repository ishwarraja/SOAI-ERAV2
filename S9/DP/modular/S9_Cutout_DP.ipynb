{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishwarraja/SOAI-ERAV2/blob/main/S9/DP/modular/S9_Cutout_DP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bC24oY_9FgaG"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sLxOzAGWFgaL"
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-WjHvfN4FgaL"
      },
      "outputs": [],
      "source": [
        "means = [0.4914, 0.4822, 0.4465]\n",
        "stds = [0.2470, 0.2435, 0.2616]\n",
        "\n",
        "train_transforms = A.Compose(\n",
        "    [\n",
        "        A.Normalize(mean=means, std=stds, always_apply=True),\n",
        "        A.PadIfNeeded(min_height=40, min_width=40, always_apply=True),\n",
        "        A.RandomCrop(height=32, width=32, always_apply=True),\n",
        "        A.HorizontalFlip(),\n",
        "        A.CoarseDropout(max_holes=1, max_height=8, max_width=8, min_holes=1, min_height=8, min_width=8, fill_value=means),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "test_transforms = A.Compose(\n",
        "    [\n",
        "        A.Normalize(mean=means, std=stds, always_apply=True),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QccdYHMhFgaM"
      },
      "outputs": [],
      "source": [
        "class Cifar10SearchDataset(datasets.CIFAR10):\n",
        "    def __init__(self, root=\"~/data\", train=True, download=True, transform=None):\n",
        "        super().__init__(root=root, train=train, download=download, transform=transform)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.data[index], self.targets[index]\n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=image)\n",
        "            image = transformed[\"image\"]\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRlYbMOwFgaN",
        "outputId": "f8228cff-68e4-4fe7-a66f-cc5e1bcdf54d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 29457704.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train = Cifar10SearchDataset(root='./data', train=True,download=True, transform=train_transforms)\n",
        "test = Cifar10SearchDataset(root='./data', train=False,download=True, transform=test_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2NHEYXVFgaP",
        "outputId": "a804be69-4457-44b6-e27a-2aeb3c6dc4ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available? True\n"
          ]
        }
      ],
      "source": [
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(shuffle=True, batch_size=512, num_workers=0, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "TidhYvGmFgaP",
        "outputId": "d06de561-e1ed-484a-cb9a-53ad6255e4b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ship  bird  cat   dog  \n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "import torchvision\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images[:4]))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Fbs4FdC7FgaQ"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "dropout_value = 0.1\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # CONVOLUTION BLOCK 1 input 32/1/1\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 32/3/1\n",
        "\n",
        "\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 32/5/1\n",
        "\n",
        "        # TRANSITION BLOCK 1\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=64,\n",
        "                out_channels=32,\n",
        "                kernel_size=(3,3),\n",
        "                padding=2,\n",
        "                stride=2,\n",
        "                dilation=2,\n",
        "                bias=False),\n",
        "        ) # output_size = 16/7/2\n",
        "\n",
        "        # CONVOLUTION BLOCK 2\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 16/11/2\n",
        "\n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 16/15/2\n",
        "\n",
        "        # TRANSITION BLOCK 2\n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64,\n",
        "                      out_channels=32,\n",
        "                      kernel_size=(3,3),\n",
        "                      padding=2,\n",
        "                      dilation=2,\n",
        "                      stride=2,\n",
        "                      bias=False),\n",
        "        ) # output_size = 8/19/4\n",
        "\n",
        "        self.convblock7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 8/24/4\n",
        "        self.convblock8 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 8/32/4\n",
        "\n",
        "        self.convblock9 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 6/40/4\n",
        "\n",
        "        # OUTPUT BLOCK\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=6)\n",
        "        ) # output_size = 1/64\n",
        "\n",
        "        self.convblock10 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
        "            # nn.BatchNorm2d(10),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Dropout(dropout_value)\n",
        "        )\n",
        "\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_value)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.convblock5(x)\n",
        "        x = self.convblock6(x)\n",
        "        x = self.convblock7(x)\n",
        "        x = self.convblock8(x)\n",
        "        x = self.convblock9(x)\n",
        "        x = self.gap(x)\n",
        "        x = self.convblock10(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXkA1ZugFgaR",
        "outputId": "5f2babab-f3d4-4e47-d41e-3e230fbf174d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             864\n",
            "              ReLU-2           [-1, 32, 32, 32]               0\n",
            "       BatchNorm2d-3           [-1, 32, 32, 32]              64\n",
            "           Dropout-4           [-1, 32, 32, 32]               0\n",
            "            Conv2d-5           [-1, 64, 32, 32]          18,432\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "       BatchNorm2d-7           [-1, 64, 32, 32]             128\n",
            "           Dropout-8           [-1, 64, 32, 32]               0\n",
            "            Conv2d-9           [-1, 32, 16, 16]          18,432\n",
            "           Conv2d-10           [-1, 64, 16, 16]          18,432\n",
            "             ReLU-11           [-1, 64, 16, 16]               0\n",
            "      BatchNorm2d-12           [-1, 64, 16, 16]             128\n",
            "          Dropout-13           [-1, 64, 16, 16]               0\n",
            "           Conv2d-14           [-1, 64, 16, 16]          36,864\n",
            "             ReLU-15           [-1, 64, 16, 16]               0\n",
            "      BatchNorm2d-16           [-1, 64, 16, 16]             128\n",
            "          Dropout-17           [-1, 64, 16, 16]               0\n",
            "           Conv2d-18             [-1, 32, 8, 8]          18,432\n",
            "           Conv2d-19             [-1, 64, 8, 8]          18,432\n",
            "             ReLU-20             [-1, 64, 8, 8]               0\n",
            "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
            "          Dropout-22             [-1, 64, 8, 8]               0\n",
            "           Conv2d-23             [-1, 64, 8, 8]          36,864\n",
            "             ReLU-24             [-1, 64, 8, 8]               0\n",
            "      BatchNorm2d-25             [-1, 64, 8, 8]             128\n",
            "          Dropout-26             [-1, 64, 8, 8]               0\n",
            "           Conv2d-27             [-1, 64, 6, 6]          36,864\n",
            "             ReLU-28             [-1, 64, 6, 6]               0\n",
            "      BatchNorm2d-29             [-1, 64, 6, 6]             128\n",
            "          Dropout-30             [-1, 64, 6, 6]               0\n",
            "        AvgPool2d-31             [-1, 64, 1, 1]               0\n",
            "           Conv2d-32             [-1, 10, 1, 1]             640\n",
            "================================================================\n",
            "Total params: 205,088\n",
            "Trainable params: 205,088\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 4.40\n",
            "Params size (MB): 0.78\n",
            "Estimated Total Size (MB): 5.19\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-UvOfk2NFgaS"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes.\n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "\n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkonHNOXFgaU",
        "outputId": "6dfbc851-b63c-431b-e070-0725d46374dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.5306025743484497 Batch_id=97 Accuracy=34.52: 100%|██████████| 98/98 [00:24<00:00,  4.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4692, Accuracy: 4644/10000 (46.44%)\n",
            "\n",
            "EPOCH: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.3664166927337646 Batch_id=97 Accuracy=50.27: 100%|██████████| 98/98 [00:15<00:00,  6.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.2022, Accuracy: 5625/10000 (56.25%)\n",
            "\n",
            "EPOCH: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.1003308296203613 Batch_id=97 Accuracy=57.56: 100%|██████████| 98/98 [00:15<00:00,  6.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.0609, Accuracy: 6162/10000 (61.62%)\n",
            "\n",
            "EPOCH: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9022022485733032 Batch_id=97 Accuracy=62.04: 100%|██████████| 98/98 [00:16<00:00,  6.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.9520, Accuracy: 6614/10000 (66.14%)\n",
            "\n",
            "EPOCH: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9412804841995239 Batch_id=97 Accuracy=64.94: 100%|██████████| 98/98 [00:15<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.8743, Accuracy: 6880/10000 (68.80%)\n",
            "\n",
            "EPOCH: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9035664796829224 Batch_id=97 Accuracy=67.06: 100%|██████████| 98/98 [00:15<00:00,  6.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.8111, Accuracy: 7110/10000 (71.10%)\n",
            "\n",
            "EPOCH: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.8388769030570984 Batch_id=97 Accuracy=69.20: 100%|██████████| 98/98 [00:17<00:00,  5.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.8010, Accuracy: 7158/10000 (71.58%)\n",
            "\n",
            "EPOCH: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.8549939393997192 Batch_id=97 Accuracy=70.50: 100%|██████████| 98/98 [00:15<00:00,  6.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.7313, Accuracy: 7418/10000 (74.18%)\n",
            "\n",
            "EPOCH: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.8037294745445251 Batch_id=97 Accuracy=71.65: 100%|██████████| 98/98 [00:15<00:00,  6.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.7252, Accuracy: 7476/10000 (74.76%)\n",
            "\n",
            "EPOCH: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6963337659835815 Batch_id=97 Accuracy=73.22: 100%|██████████| 98/98 [00:15<00:00,  6.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.7050, Accuracy: 7515/10000 (75.15%)\n",
            "\n",
            "EPOCH: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6496350169181824 Batch_id=97 Accuracy=73.88: 100%|██████████| 98/98 [00:15<00:00,  6.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6393, Accuracy: 7778/10000 (77.78%)\n",
            "\n",
            "EPOCH: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.7357432246208191 Batch_id=97 Accuracy=74.60: 100%|██████████| 98/98 [00:15<00:00,  6.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6484, Accuracy: 7785/10000 (77.85%)\n",
            "\n",
            "EPOCH: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6660345792770386 Batch_id=97 Accuracy=75.58: 100%|██████████| 98/98 [00:16<00:00,  6.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6421, Accuracy: 7780/10000 (77.80%)\n",
            "\n",
            "EPOCH: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.772645115852356 Batch_id=97 Accuracy=76.35: 100%|██████████| 98/98 [00:15<00:00,  6.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6013, Accuracy: 7927/10000 (79.27%)\n",
            "\n",
            "EPOCH: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6342002749443054 Batch_id=97 Accuracy=77.18: 100%|██████████| 98/98 [00:15<00:00,  6.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5813, Accuracy: 8007/10000 (80.07%)\n",
            "\n",
            "EPOCH: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6038535237312317 Batch_id=97 Accuracy=77.48: 100%|██████████| 98/98 [00:16<00:00,  6.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5386, Accuracy: 8159/10000 (81.59%)\n",
            "\n",
            "EPOCH: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.7010630965232849 Batch_id=97 Accuracy=78.24: 100%|██████████| 98/98 [00:15<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5477, Accuracy: 8128/10000 (81.28%)\n",
            "\n",
            "EPOCH: 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6838103532791138 Batch_id=97 Accuracy=78.55: 100%|██████████| 98/98 [00:15<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5565, Accuracy: 8089/10000 (80.89%)\n",
            "\n",
            "EPOCH: 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5948417782783508 Batch_id=97 Accuracy=79.39: 100%|██████████| 98/98 [00:16<00:00,  5.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5330, Accuracy: 8175/10000 (81.75%)\n",
            "\n",
            "EPOCH: 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6692773699760437 Batch_id=97 Accuracy=79.48: 100%|██████████| 98/98 [00:15<00:00,  6.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5137, Accuracy: 8181/10000 (81.81%)\n",
            "\n",
            "EPOCH: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.61407470703125 Batch_id=97 Accuracy=79.80: 100%|██████████| 98/98 [00:15<00:00,  6.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4949, Accuracy: 8294/10000 (82.94%)\n",
            "\n",
            "EPOCH: 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6485224962234497 Batch_id=97 Accuracy=80.08: 100%|██████████| 98/98 [00:16<00:00,  5.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5130, Accuracy: 8251/10000 (82.51%)\n",
            "\n",
            "EPOCH: 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5061438679695129 Batch_id=97 Accuracy=80.53: 100%|██████████| 98/98 [00:15<00:00,  6.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4918, Accuracy: 8319/10000 (83.19%)\n",
            "\n",
            "EPOCH: 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5787820816040039 Batch_id=97 Accuracy=80.80: 100%|██████████| 98/98 [00:15<00:00,  6.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4933, Accuracy: 8317/10000 (83.17%)\n",
            "\n",
            "EPOCH: 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6253159642219543 Batch_id=97 Accuracy=81.11: 100%|██████████| 98/98 [00:16<00:00,  6.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4984, Accuracy: 8274/10000 (82.74%)\n",
            "\n",
            "EPOCH: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5613186955451965 Batch_id=97 Accuracy=81.22: 100%|██████████| 98/98 [00:15<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4794, Accuracy: 8367/10000 (83.67%)\n",
            "\n",
            "EPOCH: 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4423721730709076 Batch_id=97 Accuracy=81.48: 100%|██████████| 98/98 [00:15<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4800, Accuracy: 8356/10000 (83.56%)\n",
            "\n",
            "EPOCH: 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5200824737548828 Batch_id=97 Accuracy=81.63: 100%|██████████| 98/98 [00:15<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4721, Accuracy: 8364/10000 (83.64%)\n",
            "\n",
            "EPOCH: 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5215268135070801 Batch_id=97 Accuracy=81.50: 100%|██████████| 98/98 [00:15<00:00,  6.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4568, Accuracy: 8472/10000 (84.72%)\n",
            "\n",
            "EPOCH: 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4716106653213501 Batch_id=97 Accuracy=82.27: 100%|██████████| 98/98 [00:15<00:00,  6.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4483, Accuracy: 8472/10000 (84.72%)\n",
            "\n",
            "EPOCH: 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.525728702545166 Batch_id=97 Accuracy=82.41: 100%|██████████| 98/98 [00:15<00:00,  6.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4400, Accuracy: 8505/10000 (85.05%)\n",
            "\n",
            "EPOCH: 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.44732406735420227 Batch_id=97 Accuracy=82.93: 100%|██████████| 98/98 [00:15<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4306, Accuracy: 8544/10000 (85.44%)\n",
            "\n",
            "EPOCH: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6036876440048218 Batch_id=97 Accuracy=82.83: 100%|██████████| 98/98 [00:15<00:00,  6.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4417, Accuracy: 8502/10000 (85.02%)\n",
            "\n",
            "EPOCH: 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5056478977203369 Batch_id=97 Accuracy=82.97: 100%|██████████| 98/98 [00:15<00:00,  6.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4591, Accuracy: 8458/10000 (84.58%)\n",
            "\n",
            "EPOCH: 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5190901756286621 Batch_id=97 Accuracy=83.17: 100%|██████████| 98/98 [00:15<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4498, Accuracy: 8478/10000 (84.78%)\n",
            "\n",
            "EPOCH: 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5393794178962708 Batch_id=97 Accuracy=83.45: 100%|██████████| 98/98 [00:15<00:00,  6.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4251, Accuracy: 8546/10000 (85.46%)\n",
            "\n",
            "EPOCH: 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5481693148612976 Batch_id=97 Accuracy=83.59: 100%|██████████| 98/98 [00:15<00:00,  6.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4492, Accuracy: 8449/10000 (84.49%)\n",
            "\n",
            "EPOCH: 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4505653381347656 Batch_id=97 Accuracy=83.60: 100%|██████████| 98/98 [00:15<00:00,  6.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4229, Accuracy: 8581/10000 (85.81%)\n",
            "\n",
            "EPOCH: 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.45262837409973145 Batch_id=97 Accuracy=83.68: 100%|██████████| 98/98 [00:15<00:00,  6.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4188, Accuracy: 8585/10000 (85.85%)\n",
            "\n",
            "EPOCH: 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4515673816204071 Batch_id=97 Accuracy=84.02: 100%|██████████| 98/98 [00:15<00:00,  6.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4119, Accuracy: 8567/10000 (85.67%)\n",
            "\n",
            "EPOCH: 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4555342197418213 Batch_id=97 Accuracy=84.23: 100%|██████████| 98/98 [00:15<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4179, Accuracy: 8602/10000 (86.02%)\n",
            "\n",
            "EPOCH: 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.500921368598938 Batch_id=97 Accuracy=84.40: 100%|██████████| 98/98 [00:15<00:00,  6.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4222, Accuracy: 8572/10000 (85.72%)\n",
            "\n",
            "EPOCH: 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4668918251991272 Batch_id=97 Accuracy=84.42: 100%|██████████| 98/98 [00:15<00:00,  6.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4114, Accuracy: 8597/10000 (85.97%)\n",
            "\n",
            "EPOCH: 43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4687202572822571 Batch_id=97 Accuracy=84.67: 100%|██████████| 98/98 [00:15<00:00,  6.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4071, Accuracy: 8612/10000 (86.12%)\n",
            "\n",
            "EPOCH: 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4080903232097626 Batch_id=97 Accuracy=84.72: 100%|██████████| 98/98 [00:15<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4032, Accuracy: 8625/10000 (86.25%)\n",
            "\n",
            "EPOCH: 45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4184328317642212 Batch_id=97 Accuracy=84.72: 100%|██████████| 98/98 [00:15<00:00,  6.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.3954, Accuracy: 8663/10000 (86.63%)\n",
            "\n",
            "EPOCH: 46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4788418412208557 Batch_id=97 Accuracy=84.89: 100%|██████████| 98/98 [00:15<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4100, Accuracy: 8606/10000 (86.06%)\n",
            "\n",
            "EPOCH: 47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4403032660484314 Batch_id=97 Accuracy=85.15: 100%|██████████| 98/98 [00:15<00:00,  6.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.3974, Accuracy: 8660/10000 (86.60%)\n",
            "\n",
            "EPOCH: 48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.45939382910728455 Batch_id=97 Accuracy=85.09: 100%|██████████| 98/98 [00:15<00:00,  6.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4229, Accuracy: 8589/10000 (85.89%)\n",
            "\n",
            "EPOCH: 49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.39419668912887573 Batch_id=97 Accuracy=85.15: 100%|██████████| 98/98 [00:15<00:00,  6.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4073, Accuracy: 8603/10000 (86.03%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "# scheduler = StepLR(optimizer, step_size=6, gamma=0.1)\n",
        "\n",
        "\n",
        "EPOCHS = 50\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    # scheduler.step()\n",
        "    test(model, device, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yTq-M6vnFgaU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpO5o6ILFgaV",
        "outputId": "afa413b9-66ee-4152-8ef3-92a680dea60b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has a receptive field size is less. 43\n"
          ]
        }
      ],
      "source": [
        "# Count the Number of Receptive Field for the Model\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# from model import Net\n",
        "\n",
        "def get_receptive_field(model):\n",
        "    receptive_field = 1\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            dilation = module.dilation[0]\n",
        "            kernel_size = module.kernel_size[0]\n",
        "            stride = module.stride[0]\n",
        "            receptive_field = (receptive_field - 1) * stride + dilation * (kernel_size - 1) + 1\n",
        "        elif isinstance(module, nn.MaxPool2d):\n",
        "            kernel_size = module.kernel_size\n",
        "            stride = module.stride\n",
        "            receptive_field = (receptive_field - 1) * stride + kernel_size\n",
        "\n",
        "    return receptive_field\n",
        "\n",
        "# Create an instance of your model\n",
        "model = Net()\n",
        "\n",
        "# Calculate the receptive field\n",
        "receptive_field_size = get_receptive_field(model)\n",
        "\n",
        "# Check if the receptive field size is less than 44\n",
        "if receptive_field_size < 44:\n",
        "    print(\"The model has a receptive field size is less.\",receptive_field_size)\n",
        "else:\n",
        "    print(\"The model has a receptive field size of 44 or more.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tzwgwDzFgaV",
        "outputId": "3177da30-35dc-4313-9a8b-249170308ee4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (convblock1): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (convblock2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (convblock3): Sequential(\n",
              "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "  )\n",
              "  (convblock4): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (convblock5): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (convblock6): Sequential(\n",
              "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "  )\n",
              "  (convblock7): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (convblock8): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (convblock9): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (gap): Sequential(\n",
              "    (0): AvgPool2d(kernel_size=6, stride=6, padding=0)\n",
              "  )\n",
              "  (convblock10): Sequential(\n",
              "    (0): Conv2d(64, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjuOXexKFgaV",
        "outputId": "117dc44e-3284-46f8-a781-ba01b81ea149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total convolution layers: 10\n",
            "conv_layers\n"
          ]
        }
      ],
      "source": [
        "# we will save the conv layer weights in this list\n",
        "model_weights =[]\n",
        "#we will save the 49 conv layers in this list\n",
        "conv_layers = []\n",
        "# get all the model children as list\n",
        "model_children = list(model.children())\n",
        "#counter to keep count of the conv layers\n",
        "counter = 0\n",
        "#append all the conv layers and their respective wights to the list\n",
        "\n",
        "model_children = model.children()\n",
        "for children in model_children:\n",
        "    if type(children) == nn.Sequential:\n",
        "        for child in children:\n",
        "            if type(child) == nn.Conv2d:\n",
        "                counter += 1\n",
        "                model_weights.append(child.weight)\n",
        "                conv_layers.append(child)\n",
        "\n",
        "print(f\"Total convolution layers: {counter}\")\n",
        "print(\"conv_layers\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b8fbfcbe0e544000e4ba3d2d9974592a7ba1a2af52205db5302ae41a0c45d995"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}